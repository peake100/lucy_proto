syntax = "proto3";
package lucy;
option go_package = "github.com/peake100/lucy-go/lucy";

import "cereal_proto/uuid.proto";
import "google/protobuf/empty.proto";
import "lucy_proto/create.proto";
import "lucy_proto/jobs.proto";
import "lucy_proto/updates.proto";

// Lucy is a service for creating and tracking jobs. The gRPC portion of the service
// handles creating and updating jobs. Job distribution is handled through RabbitMQ.
service Lucy {
  // CreateBatch creates a new batch.
  rpc CreateBatch(lucy.NewBatch) returns (lucy.CreatedBatch);

  // Batch returns a single batch for a given id.
  rpc GetBatch(cereal.UUID) returns (lucy.Batch);

  // List batches lists all batches from newest to oldest.
  rpc ListBatches(google.protobuf.Empty) returns (stream lucy.Batch);

  // CreateJob creates a new job and returns an id for fetching it.
  rpc CreateJobs(lucy.NewJobs) returns (lucy.CreatedJobs);

  // GetJob fetches a single job.
  rpc GetJob(cereal.UUID) returns (lucy.Job);

  // GetBatchJobs returns the jobs for a given batch.
  rpc GetBatchJobs(cereal.UUID) returns (lucy.BatchJobs);

  // StartStage starts a job stage.
  rpc StartStage(lucy.StartStage) returns (google.protobuf.Empty);

  // ProgressStage updates the progress on a stage.
  rpc ProgressStage(lucy.ProgressStage) returns (google.protobuf.Empty);

  // CompleteStage completes a stage with result data.
  rpc CompleteStage(lucy.CompleteStage) returns (google.protobuf.Empty);

  // RunnerUpdate allows a job runner to stream updates to Lucy, removing the overhead
  // of making individual rpc requests for every update.
  //
  // The stage_id of the first message MUST be set, but subsequent messages can omit
  // the id when updating the same stage.
  //
  // Progress updates to the DB are captured and throttled, allowing only 12 updates
  // per second to reduce load on the DB. The service will trap progress updates, then
  // once every 1/12th of a second, send the latest received to the DB.
  //
  // If an error occurs, the details on the pkerr.Error will include the number of the
  // update that caused the error. Update numbers start at 0, and are tracked in order
  // as they are received.
  //
  // It is recommended that each stream only be sent a single job at a time, though this
  // recommendation is not enforced. For workers running multiple jobs in parallel,
  // consider opening a separate Runner for each parallel job.
  //
  // When The server receives a confirm request, it will send back an emtpy message
  // confirming that all previously sent requests have been processed without error.
  rpc Runner(stream lucy.RunnerUpdate) returns (stream google.protobuf.Empty);

  // CancelBatch cancels all jobs in the passed batches.
  rpc CancelBatches(lucy.CancelBatches) returns (google.protobuf.Empty);

  // CancelJobs cancels all jobs listed.
  rpc CancelJob(cereal.UUID) returns (google.protobuf.Empty);
}
